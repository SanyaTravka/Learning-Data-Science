{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "425b2e1f",
   "metadata": {},
   "source": [
    "# Домашнее задание 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d404ca0",
   "metadata": {},
   "source": [
    "Добро пожаловать на третье домашнее задание, в нем Вам подсчитать метрики бинарной классификации:  **Accuracy, Precision,  Recall и F1** на валидационном датасете для двух моделей. В итоге Вам предстоит выбрать лучшую по качеству модель.\n",
    "\n",
    "В этом наборе данных находиться информация о людях: возраст человека, возраст его родителей, **ходит ли он в школу или нет, а также предсказания 2-ух обученных независимо моделей для всех объектов из валидационного датасета**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d718034e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"school_homework_metrics_2_models__10cye.csv\", index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13f23270",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Возраст</th>\n",
       "      <th>Возраст_мамы</th>\n",
       "      <th>Возраст_папы</th>\n",
       "      <th>Answer</th>\n",
       "      <th>Prediction</th>\n",
       "      <th>Prediction2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>44</td>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12</td>\n",
       "      <td>61</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>43</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>46</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>65</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>15</td>\n",
       "      <td>47</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>11</td>\n",
       "      <td>69</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>14</td>\n",
       "      <td>61</td>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>11</td>\n",
       "      <td>69</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>7</td>\n",
       "      <td>63</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1001 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Возраст  Возраст_мамы  Возраст_папы  Answer  Prediction  Prediction2\n",
       "id                                                                       \n",
       "0          6            44            58       0           1            0\n",
       "1         12            61            56       0           0            0\n",
       "2          8            43            43       0           1            0\n",
       "3          5            46            57       0           1            0\n",
       "4          5            65            51       1           1            0\n",
       "..       ...           ...           ...     ...         ...          ...\n",
       "995       15            47            61       0           1            1\n",
       "996       11            69            60       1           0            1\n",
       "997       14            61            65       1           1            1\n",
       "998       11            69            53       1           1            1\n",
       "999        7            63            70       0           0            1\n",
       "\n",
       "[1001 rows x 6 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d317dd",
   "metadata": {},
   "source": [
    "### Задание 1\n",
    "\n",
    "Удалите из валидационного датасета столбцы **Возраст, Возраст_мамы и Возраст_папы**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4d13f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop([\"Возраст\", \"Возраст_мамы\", \"Возраст_папы\"],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defa1eee",
   "metadata": {},
   "source": [
    "**Проверьте себя!**\n",
    "\n",
    "Убедитесь с помощью команды <code>assert()</code>, что Вы правильно выполнили текущее задание."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43f0f7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(df.columns) == 3, \"Удалены не все лишние столбцы\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9415ad96",
   "metadata": {},
   "source": [
    "### Задание 2.1\n",
    "\n",
    "Реализуйте функцию для подсчета метрики **Accuracy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "382e123b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric_accuracy(answer, prediction):\n",
    "    \n",
    "    len_dataset = len(answer)\n",
    "    \n",
    "    count_trues = 0\n",
    "    \n",
    "    for m,n in zip(answer, prediction):\n",
    "        if m==n:\n",
    "            count_trues+=1\n",
    "            \n",
    "    return count_trues/len_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b192f44",
   "metadata": {},
   "source": [
    "подсчитайте метрику **Accuracy** на валидационном датасете для первой и второй модели и сохраните эти числа в переменные <code>metric_accuracy_custom_1</code> и <code>metric_accuracy_custom_2</code> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab8bc458",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_accuracy_custom_1 = metric_accuracy(df[\"Answer\"], df[\"Prediction\"])\n",
    "metric_accuracy_custom_2 = metric_accuracy(df[\"Answer\"], df[\"Prediction2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c24fccd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5174825174825175 0.4725274725274725\n"
     ]
    }
   ],
   "source": [
    "print(metric_accuracy_custom_1,metric_accuracy_custom_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a202b74b",
   "metadata": {},
   "source": [
    "Сравните две модели по метрике **Accuracy**, какая из них оказалась лучше?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c286af",
   "metadata": {},
   "source": [
    "### Задание 2.2\n",
    "\n",
    "Подсчитайте метрику **Accuracy** с помощью библиотеки <code>sklearn</code> для первой и второй модели и сохраните эти числа в переменные <code>metric_accuracy_sklearn_1</code> и <code>metric_accuracy_sklearn_2</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e158178d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "metric_accuracy_sklearn_1 = accuracy_score(df[\"Answer\"], df[\"Prediction\"])\n",
    "metric_accuracy_sklearn_2 = accuracy_score(df[\"Answer\"], df[\"Prediction2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0cbede7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5174825174825175 0.4725274725274725\n"
     ]
    }
   ],
   "source": [
    "print(metric_accuracy_sklearn_1,metric_accuracy_sklearn_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c3cde0",
   "metadata": {},
   "source": [
    "**Проверьте себя!**\n",
    "\n",
    "Убедитесь с помощью команды <code>assert()</code>, что ответ Вашей функции **metric_accuracy** совпадает с аналогичным методом из библиотеки <code>sklearn</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "52f8f5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert metric_accuracy_sklearn_1 == metric_accuracy_custom_1, \"Неправильный подсчет метрики\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1c3470b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert metric_accuracy_sklearn_2 == metric_accuracy_custom_2, \"Неправильный подсчет метрики\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "188b7bdc",
   "metadata": {},
   "source": [
    "### Задание 3.1\n",
    "\n",
    "Реализуйте функцию для подсчета метрики **Precision**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "402161fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric_precision(answer, prediction):\n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    for m,n in zip(answer, prediction):\n",
    "        if m==1 and n==1:\n",
    "            tp+=1\n",
    "        elif n==1 and m==0:\n",
    "            fp+=1\n",
    "    return tp/(tp+fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7502f6c3",
   "metadata": {},
   "source": [
    "подсчитайте метрику **Precision**  на валидационном датасете для первой и второй модели и сохраните эти числа в переменные <code>metric_precision_custom_1</code> и <code>metric_precision_custom_2</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4208d3b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1adb0670",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_precision_custom_1 = metric_precision(df[\"Answer\"], df[\"Prediction\"])\n",
    "metric_precision_custom_2 = metric_precision(df[\"Answer\"], df[\"Prediction2\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e4bc120",
   "metadata": {},
   "source": [
    "Сравните две модели по метрике **Precision**, какая из них оказалась лучше?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9c100c97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5088832487309645 0.469061876247505\n"
     ]
    }
   ],
   "source": [
    "print(metric_precision_custom_1,metric_precision_custom_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "291464db",
   "metadata": {},
   "source": [
    "### Задание 3.2\n",
    "\n",
    "Подсчитайте метрику **Precision** с помощью библиотеки <code>sklearn</code> для первой и второй модели и сохраните эти числа в переменные <code>metric_precision_sklearn_1</code> и <code>metric_precision_sklearn_2</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0099f9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "metric_precision_sklearn_1 = precision_score(df[\"Answer\"], df[\"Prediction\"])\n",
    "metric_precision_sklearn_2 = precision_score(df[\"Answer\"], df[\"Prediction2\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b75b31a5",
   "metadata": {},
   "source": [
    "**Проверьте себя!**\n",
    "\n",
    "Убедитесь с помощью команды <code>assert()</code>, что ответ Вашей функции **metric_precision** совпадает с аналогичным методом из библиотеки <code>sklearn</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1ffaccbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert metric_precision_sklearn_1 == metric_precision_custom_1, \"Неправильный подсчет метрики\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c99b336d",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert metric_precision_sklearn_2 == metric_precision_custom_2, \"Неправильный подсчет метрики\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b1c270",
   "metadata": {},
   "source": [
    "### Задание 4.1\n",
    "\n",
    "Реализуйте функцию для подсчета метрики **Recall**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "634860bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric_recall(answer, prediction):\n",
    "    tp = 0\n",
    "    fn = 0\n",
    "    for m,n in zip(answer,prediction):\n",
    "        if m==1 and n==1:\n",
    "            tp+=1\n",
    "        elif m==1 and n==0:\n",
    "            fn+=1\n",
    "            \n",
    "    return tp/(tp+fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d9821d",
   "metadata": {},
   "source": [
    "подсчитайте метрику **Recall** на валидационном датасете для первой и второй модели и сохраните эти числа в переменные  <code>metric_recall_custom_1</code> и  <code>metric_recall_custom_2</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9a633e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_recall_custom_1 = metric_recall(df[\"Answer\"], df[\"Prediction\"])\n",
    "metric_recall_custom_2 = metric_recall(df[\"Answer\"], df[\"Prediction2\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e598e511",
   "metadata": {},
   "source": [
    "Сравните две модели по метрике **Recall**, какая из них оказалась лучше?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "51b8210e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.806841046277666 0.47283702213279677\n"
     ]
    }
   ],
   "source": [
    "print(metric_recall_custom_1,metric_recall_custom_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "020f8545",
   "metadata": {},
   "source": [
    "### Задание 4.2\n",
    "\n",
    "Подсчитайте метрику **Recall** с помощью библиотеки <code>sklearn</code> для первой и второй модели и сохраните эти числа в переменные <code>metric_recall_sklearn_1</code> и <code>metric_recall_sklearn_2</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9901a7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "metric_recall_sklearn_1 = recall_score(df[\"Answer\"], df[\"Prediction\"])\n",
    "metric_recall_sklearn_2 = recall_score(df[\"Answer\"], df[\"Prediction2\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd7bf66c",
   "metadata": {},
   "source": [
    "**Проверьте себя!**\n",
    "\n",
    "Убедитесь с помощью команды <code>assert()</code>, что ответ Вашей функции **metric_recall** совпадает с аналогичным методом из библиотеки <code>sklearn</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fb00cd03",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert metric_recall_sklearn_1 == metric_recall_custom_1, \"Неправильный подсчет метрики\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6c345ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert metric_recall_sklearn_2 == metric_recall_custom_2, \"Неправильный подсчет метрики\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d54eec",
   "metadata": {},
   "source": [
    "### Задание 5.1\n",
    "\n",
    "Реализуйте функцию для подсчета метрики **F1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9a47f8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric_f1(answer, prediction):\n",
    "    precision = metric_precision(answer,prediction)\n",
    "    recal = metric_recall(answer,prediction)\n",
    "    return (2*precision*recal)/(precision+recal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c7df0fd",
   "metadata": {},
   "source": [
    "подсчитайте метрику **F1** на валидационном датасете для первой и второй модели и сохраните эти числа в переменные <code>metric_f1_custom_1</code> и  <code>metric_f1_custom_2</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "81e1d3f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_f1_custom_1 = metric_f1(df[\"Answer\"], df[\"Prediction\"])\n",
    "metric_f1_custom_2 = metric_f1(df[\"Answer\"], df[\"Prediction2\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56dec0fd",
   "metadata": {},
   "source": [
    "Сравните две модели по метрике **F1**, какая из них оказалась лучше?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "03a2de6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6241245136186772 0.47094188376753504\n"
     ]
    }
   ],
   "source": [
    "print(metric_f1_custom_1,metric_f1_custom_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a2c9e7",
   "metadata": {},
   "source": [
    "### Задание 5.2\n",
    "\n",
    "Подсчитайте метрику **F1** с помощью библиотеки <code>sklearn</code> для первой и второй модели и сохраните эти числа в переменные <code>metric_f1_sklearn_1</code> и <code>metric_f1_sklearn_2</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fc956eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "metric_f1_sklearn_1 = f1_score(df[\"Answer\"], df[\"Prediction\"])\n",
    "metric_f1_sklearn_2 = f1_score(df[\"Answer\"], df[\"Prediction2\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b8651d2",
   "metadata": {},
   "source": [
    "**Проверьте себя!**\n",
    "\n",
    "Убедитесь с помощью команды <code>assert()</code>, что ответ Вашей функции **metric_f1** совпадает с аналогичным методом из библиотеки <code>sklearn</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0ae88d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert metric_f1_sklearn_1 == metric_f1_custom_1, \"Неправильный подсчет метрики\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3a700703",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert metric_f1_sklearn_2 == metric_f1_custom_2, \"Неправильный подсчет метрики\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6869e86a",
   "metadata": {},
   "source": [
    "И так, поздравляем, Вы выполнили третье домашнее задание!\n",
    "\n",
    "Теперь осталось чуть-чуть...\n",
    "\n",
    "На платформу Школково Вам нужно будет загрузить таблицу с метриками **Accuracy, Precision, Recall и F1** для лучшей модели измеренные на валидационном датасете.\n",
    "\n",
    "Чтобы сделать это, выполните ячейку ниже, но сперва выбрав нужную модель (ее метрики). Тем самым Вы получите нужную таблицу. Затем загрузите данный файл на платформу Школково."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "85fce45b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length of values (2) does not match length of index (1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df_rezults \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m                    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mmetric_accuracy_custom_1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric_precision_custom_1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric_recall_custom_1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric_f1_custom_1\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m                    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mmetric_accuracy_custom_2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric_precision_custom_2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric_recall_custom_2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric_f1_custom_2\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m                    \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mAccuracy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mPrecision\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mRecall\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mF1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:754\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    745\u001b[0m         columns \u001b[38;5;241m=\u001b[39m ensure_index(columns)\n\u001b[0;32m    746\u001b[0m     arrays, columns, index \u001b[38;5;241m=\u001b[39m nested_data_to_arrays(\n\u001b[0;32m    747\u001b[0m         \u001b[38;5;66;03m# error: Argument 3 to \"nested_data_to_arrays\" has incompatible\u001b[39;00m\n\u001b[0;32m    748\u001b[0m         \u001b[38;5;66;03m# type \"Optional[Collection[Any]]\"; expected \"Optional[Index]\"\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    752\u001b[0m         dtype,\n\u001b[0;32m    753\u001b[0m     )\n\u001b[1;32m--> 754\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[43marrays_to_mgr\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    755\u001b[0m \u001b[43m        \u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    756\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    757\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    758\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    759\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    760\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    761\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    762\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m ndarray_to_mgr(\n\u001b[0;32m    763\u001b[0m         data,\n\u001b[0;32m    764\u001b[0m         index,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    768\u001b[0m         typ\u001b[38;5;241m=\u001b[39mmanager,\n\u001b[0;32m    769\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py:123\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[0;32m    120\u001b[0m         index \u001b[38;5;241m=\u001b[39m ensure_index(index)\n\u001b[0;32m    122\u001b[0m     \u001b[38;5;66;03m# don't force copy because getting jammed in an ndarray anyway\u001b[39;00m\n\u001b[1;32m--> 123\u001b[0m     arrays \u001b[38;5;241m=\u001b[39m \u001b[43m_homogenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;66;03m# _homogenize ensures\u001b[39;00m\n\u001b[0;32m    125\u001b[0m     \u001b[38;5;66;03m#  - all(len(x) == len(index) for x in arrays)\u001b[39;00m\n\u001b[0;32m    126\u001b[0m     \u001b[38;5;66;03m#  - all(x.ndim == 1 for x in arrays)\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    129\u001b[0m \n\u001b[0;32m    130\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    131\u001b[0m     index \u001b[38;5;241m=\u001b[39m ensure_index(index)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py:620\u001b[0m, in \u001b[0;36m_homogenize\u001b[1;34m(data, index, dtype)\u001b[0m\n\u001b[0;32m    615\u001b[0m             val \u001b[38;5;241m=\u001b[39m lib\u001b[38;5;241m.\u001b[39mfast_multiget(val, oindex\u001b[38;5;241m.\u001b[39m_values, default\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mnan)\n\u001b[0;32m    617\u001b[0m         val \u001b[38;5;241m=\u001b[39m sanitize_array(\n\u001b[0;32m    618\u001b[0m             val, index, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, raise_cast_failure\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    619\u001b[0m         )\n\u001b[1;32m--> 620\u001b[0m         \u001b[43mcom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequire_length_match\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    622\u001b[0m     homogenized\u001b[38;5;241m.\u001b[39mappend(val)\n\u001b[0;32m    624\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m homogenized\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\common.py:571\u001b[0m, in \u001b[0;36mrequire_length_match\u001b[1;34m(data, index)\u001b[0m\n\u001b[0;32m    567\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    568\u001b[0m \u001b[38;5;124;03mCheck the length of data matches the length of the index.\u001b[39;00m\n\u001b[0;32m    569\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    570\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(index):\n\u001b[1;32m--> 571\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    572\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLength of values \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    573\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(data)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    574\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdoes not match length of index \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    575\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(index)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    576\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Length of values (2) does not match length of index (1)"
     ]
    }
   ],
   "source": [
    "df_rezults = pd.DataFrame([\n",
    "                    [metric_accuracy_custom_1, metric_precision_custom_1, metric_recall_custom_1, metric_f1_custom_1],\n",
    "                    [metric_accuracy_custom_2, metric_precision_custom_2, metric_recall_custom_2, metric_f1_custom_2]\n",
    "                    ],\n",
    "                   columns=['Accuracy', 'Precision', 'Recall', 'F1'], index=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b3ced47",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rezults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac3af76",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rezults.to_csv(\"h3_answer_prod.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
